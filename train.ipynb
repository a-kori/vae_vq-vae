{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2R88GtApjf6O"
   },
   "source": [
    "# Fachprojekt Machine Learning\n",
    "Authors: Anastasiia Korzhylova, Ivan Shishkin, Ramneek Agnihotri, Rodi Mehi\n",
    "\n",
    "**Due date:** Wednesday, 1. May 2024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cykyTX8rnQOk"
   },
   "source": [
    "## Import necessary components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import matplotlib as plt\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, CosineAnnealingLR\n",
    "\n",
    "# Import the training and the testing datasets\n",
    "from datasets import training_dataset, test_dataset\n",
    "\n",
    "# Import the evaluation and the sampling function\n",
    "from evaluation import evaluate\n",
    "from sampling import sample\n",
    "\n",
    "# Import the VAE model\n",
    "import networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X3RVtvjjrCnI"
   },
   "source": [
    "## Set the hyperparameters, learning strategy, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 217955,
     "status": "ok",
     "timestamp": 1715068292983,
     "user": {
      "displayName": "Anastasiia Korzhylova",
      "userId": "09104997838746389444"
     },
     "user_tz": -120
    },
    "id": "Yz1B0uMXkZS5",
    "outputId": "110105e5-c2c8-4dce-e579-801f08c8f97e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128 # Number of images per update of the network\n",
    "num_epochs = 50 # One epoch means seeing every image of the training dataset, which consists of 50000 images\n",
    "latent_dim = 100  # Size of the latent space\n",
    "input_channels = 3  # CIFAR-10 images have 3 color channels\n",
    "\n",
    "# Select the device that will be used for training: GPU, if available, otherwise CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "print('=========================================')\n",
    "\n",
    "# Put the neural network on the selected device\n",
    "model = networks.VAE(input_channels, latent_dim)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer selection\n",
    "optimizer_option = 'adam'\n",
    "\n",
    "optimizer = None\n",
    "if optimizer_option == \"adam\":\n",
    "  optimizer = torch.optim.Adam(model.parameters())\n",
    "elif optimizer_option == \"adamw\":\n",
    "  optimizer = torch.optim.AdamW(model.parameters())\n",
    "elif optimizer_option == \"rmsprop\":\n",
    "  optimizer = torch.optim.RMSProp(model.parameters())\n",
    "else:\n",
    "  optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "# Learning rate scheduler parameters\n",
    "lr_schedule_option = 'step'\n",
    "\n",
    "scheduler = None\n",
    "if lr_schedule_option == 'step':\n",
    "  scheduler = StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "elif lr_schedule_option == 'exponential':\n",
    "  scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "elif lr_schedule_option == 'cosine':\n",
    "  scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=0.0001)\n",
    "\n",
    "# Scaler for AMP\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Create data loaders for training and testing with the batch size from above.\n",
    "# They can do things like multiprocessing and shuffling the order of the images.\n",
    "# We can iterate over them to obtain batches of images and labels (see training loop below).\n",
    "training_loader = DataLoader(dataset=training_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "q1FNGhYG_IbQ"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loss_function() missing 2 required positional arguments: 'mu' and 'logvar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# After the epoch, evaluate the accuracy on the test dataset\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m test_losses\u001b[38;5;241m.\u001b[39mappend(mean_loss)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Mean Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Learning Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\De_Studium\\Semester-6\\ML\\G2\\evaluation.py:24\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, test_loader, loss_fun, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m---> 24\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader)\n",
      "\u001b[1;31mTypeError\u001b[0m: loss_function() missing 2 required positional arguments: 'mu' and 'logvar'"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "  BCE = nn.functional.binary_cross_entropy_with_logits(recon_x, x, reduction='sum')\n",
    "  KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "  return BCE + KLD\n",
    "\n",
    "# We want to plot training and testing losses at the end of training\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "\n",
    "  for batch_idx, (data, _) in enumerate(training_loader):\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with torch.cuda.amp.autocast():\n",
    "      # Forward pass\n",
    "      recon_batch, mu, logvar = model.forward(data)\n",
    "      \n",
    "      # Compute loss\n",
    "      loss = loss_function(recon_batch, data, mu, logvar)\n",
    "      train_losses.append(loss)\n",
    "\n",
    "    # Backward pass\n",
    "    scaler.scale(loss).backward()\n",
    "    \n",
    "    # Optimization step\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    \n",
    "  # Step the learning rate scheduler\n",
    "  lr = scheduler.get_last_lr()[0]\n",
    "  learning_rates = learning_rates.append(lr_schedule_option)\n",
    "  scheduler.step()\n",
    "\n",
    "  # After the epoch, evaluate the accuracy on the test dataset\n",
    "  mean_loss = evaluate(model, test_loader, loss_function, device)\n",
    "  test_losses.append(mean_loss)\n",
    "\n",
    "  print(f'Epoch {epoch + 1}, Mean Test Loss: {mean_loss}, Learning Rate: {lr:.6f}')\n",
    "  \n",
    "  # Generate and log images after each epoch\n",
    "  generated_images = sample(model)\n",
    "  for i, img in enumerate(generated_images):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot train and test losses\n",
    "  plt.figure(figsize=(10, 5))\n",
    "  plt.plot(train_losses, label='Train Loss')\n",
    "  plt.scatter(range(len(test_losses)), test_losses, color='red', label='Test Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.title('Train and Test Loss over Epochs')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot learning rate over time\n",
    "  plt.figure(figsize=(10, 5))\n",
    "  plt.plot(learning_rates, label='Learning Rate')\n",
    "  plt.xlabel('Batches')\n",
    "  plt.ylabel('Learning Rate')\n",
    "  plt.legend()\n",
    "  plt.title('Learning Rate over Time')\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "d25d8f77c9dea5a8c980ef8c2297485875df437f977b5aaad6473d2fbcee338b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
